{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from src.taskgym import HaydenRiskTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment\n",
    "env = HaydenRiskTrial(offer_amounts=(1,5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/bhayden/ti12/miniforge3/envs/rnn_env/lib/python3.11/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = RecurrentPPO(\"MlpLstmPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 68       |\n",
      "|    ep_rew_mean     | 96       |\n",
      "| time/              |          |\n",
      "|    fps             | 190      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 128      |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 29.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 123           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 2             |\n",
      "|    total_timesteps      | 256           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3440924e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.000355     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 298           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00056      |\n",
      "|    value_loss           | 603           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 384           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4871274e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0761        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.331         |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00115      |\n",
      "|    value_loss           | 0.769         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 39.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6644131e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.156         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.136         |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | 0.000149      |\n",
      "|    value_loss           | 0.42          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 35.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 640           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6506296e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.000636      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 586           |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 6.42e-05      |\n",
      "|    value_loss           | 1.17e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 28.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 768          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.009088e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.00405     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 72.5         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 8.99e-05     |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 34.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 896           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022554863 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.136         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.254         |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    value_loss           | 0.546         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 33            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 1024          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048526982 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.00268       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 374           |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.000693     |\n",
      "|    value_loss           | 749           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 32.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 1152          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014119456 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.00081       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 72            |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -6.93e-05     |\n",
      "|    value_loss           | 146           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 28.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 1280         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.377449e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.0206       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000314    |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 35            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 1408          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3573637e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.558        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.502         |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -6.29e-05     |\n",
      "|    value_loss           | 1.84          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 31.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 132           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3301843e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.0135        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 486           |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | 7.13e-05      |\n",
      "|    value_loss           | 979           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 68         |\n",
      "|    ep_rew_mean          | 28.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 1664       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00160236 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | -0.777     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.501      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00552   |\n",
      "|    value_loss           | 1.45       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 28.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 1792        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024350297 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.932      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0859      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.575       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.7         |\n",
      "|    ep_rew_mean          | 25.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 1920         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013787895 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.0115       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71.8         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.0006       |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 67.5          |\n",
      "|    ep_rew_mean          | 23.9          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027212314 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -0.179        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.32          |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000499     |\n",
      "|    value_loss           | 0.733         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.2         |\n",
      "|    ep_rew_mean          | 23.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 2176         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012085731 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.0781      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.275        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 0.746        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.1         |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 2304         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014854972 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.00324      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 73.2         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.00245      |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.9        |\n",
      "|    ep_rew_mean          | 20.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 2432        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020234365 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | -0.0428     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.7        |\n",
      "|    ep_rew_mean          | 19.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035740625 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | -0.275      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0812      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.6        |\n",
      "|    ep_rew_mean          | 18.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 2688        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026337603 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | -0.234      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00432     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.5        |\n",
      "|    ep_rew_mean          | 17.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 2816        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028149016 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | -0.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00774    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.0322      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.4         |\n",
      "|    ep_rew_mean          | 16.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 2944         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071935016 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.281       |\n",
      "|    explained_variance   | -0.694       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00306      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 0.0208       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.3         |\n",
      "|    ep_rew_mean          | 16           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060688113 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | -0.651       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00109     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 0.0156       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.2        |\n",
      "|    ep_rew_mean          | 15.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004339528 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.13       |\n",
      "|    explained_variance   | -1.79       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00421    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.1         |\n",
      "|    ep_rew_mean          | 14.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 3328         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047694873 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0885      |\n",
      "|    explained_variance   | -1.26        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0066      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    value_loss           | 0.013        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 66            |\n",
      "|    ep_rew_mean          | 14.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 136           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 3456          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7206337e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0638       |\n",
      "|    explained_variance   | -1.05         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00417       |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | 0.000482      |\n",
      "|    value_loss           | 0.00745       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.9          |\n",
      "|    ep_rew_mean          | 13.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 137           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 3584          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047289534 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0625       |\n",
      "|    explained_variance   | -0.466        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00292      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00343      |\n",
      "|    value_loss           | 0.0066        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.9          |\n",
      "|    ep_rew_mean          | 13.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 137           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 3712          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062575284 |\n",
      "|    clip_fraction        | 0.00391       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0658       |\n",
      "|    explained_variance   | -0.465        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00193      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00307      |\n",
      "|    value_loss           | 0.00843       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.8          |\n",
      "|    ep_rew_mean          | 12.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 137           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 3840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016182335 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0572       |\n",
      "|    explained_variance   | -0.557        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00219       |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000267     |\n",
      "|    value_loss           | 0.0057        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.7        |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 3968        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001434756 |\n",
      "|    clip_fraction        | 0.00859     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0476     |\n",
      "|    explained_variance   | -0.778      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00272    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 0.00901     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.7          |\n",
      "|    ep_rew_mean          | 11.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 137           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2864274e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0363       |\n",
      "|    explained_variance   | -0.182        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00265       |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | 0.000112      |\n",
      "|    value_loss           | 0.00514       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65.6         |\n",
      "|    ep_rew_mean          | 11.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 4224         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.140582e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0324      |\n",
      "|    explained_variance   | -0.172       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00173      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000297    |\n",
      "|    value_loss           | 0.00478      |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 65.6     |\n",
      "|    ep_rew_mean          | 11       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 138      |\n",
      "|    iterations           | 34       |\n",
      "|    time_elapsed         | 31       |\n",
      "|    total_timesteps      | 4352     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0298  |\n",
      "|    explained_variance   | -0.0878  |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0021   |\n",
      "|    n_updates            | 330      |\n",
      "|    policy_gradient_loss | 1.12e-06 |\n",
      "|    value_loss           | 0.00431  |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.5          |\n",
      "|    ep_rew_mean          | 10.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 4480          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017864862 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0277       |\n",
      "|    explained_variance   | -0.12         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000392     |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    value_loss           | 0.00492       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.5          |\n",
      "|    ep_rew_mean          | 10.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 4608          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028500333 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0224       |\n",
      "|    explained_variance   | 0.0153        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000978     |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    value_loss           | 0.00415       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65.4         |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 4736         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002328637 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0177      |\n",
      "|    explained_variance   | -0.078       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00109      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000717    |\n",
      "|    value_loss           | 0.0047       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.4          |\n",
      "|    ep_rew_mean          | 9.75          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 4864          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017787889 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0151       |\n",
      "|    explained_variance   | 0.058         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000472      |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000755     |\n",
      "|    value_loss           | 0.004         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65.4          |\n",
      "|    ep_rew_mean          | 9.48          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 4992          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8626451e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0134       |\n",
      "|    explained_variance   | 0.0808        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00191       |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | 1.07e-05      |\n",
      "|    value_loss           | 0.00388       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 65.3      |\n",
      "|    ep_rew_mean          | 9.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 138       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 5120      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0127   |\n",
      "|    explained_variance   | 0.132     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0019    |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -4.36e-06 |\n",
      "|    value_loss           | 0.00388   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_recurrent.ppo_recurrent.RecurrentPPO at 0x7f90b8c17290>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run 5000 training runs\n",
    "model.learn(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Reward = -0.5\n",
      "Episode 1: Reward = -0.5\n",
      "Episode 2: Reward = -0.6\n",
      "Episode 3: Reward = -0.5\n",
      "Episode 4: Reward = -0.5\n",
      "Episode 5: Reward = -0.5\n",
      "Episode 6: Reward = -0.5\n",
      "Episode 7: Reward = -0.6\n",
      "Episode 8: Reward = -0.6\n",
      "Episode 9: Reward = -0.5\n",
      "Episode 10: Reward = -0.5\n",
      "Episode 11: Reward = -0.5\n",
      "Episode 12: Reward = -0.5\n",
      "Episode 13: Reward = -0.5\n",
      "Episode 14: Reward = -0.5\n",
      "Episode 15: Reward = -0.5\n",
      "Episode 16: Reward = -0.5\n",
      "Episode 17: Reward = -0.6\n",
      "Episode 18: Reward = -0.5\n",
      "Episode 19: Reward = -0.5\n",
      "Episode 20: Reward = -0.5\n",
      "Episode 21: Reward = -0.5\n",
      "Episode 22: Reward = -0.6\n",
      "Episode 23: Reward = -0.5\n",
      "Episode 24: Reward = -0.5\n",
      "Episode 25: Reward = -0.5\n",
      "Episode 26: Reward = -0.6\n",
      "Episode 27: Reward = -0.5\n",
      "Episode 28: Reward = -0.5\n",
      "Episode 29: Reward = -0.5\n",
      "Episode 30: Reward = -0.5\n",
      "Episode 31: Reward = -0.5\n",
      "Episode 32: Reward = -0.5\n",
      "Episode 33: Reward = -0.5\n",
      "Episode 34: Reward = -0.6\n",
      "Episode 35: Reward = -0.5\n",
      "Episode 36: Reward = -0.5\n",
      "Episode 37: Reward = -0.5\n",
      "Episode 38: Reward = -0.5\n",
      "Episode 39: Reward = -0.5\n",
      "Episode 40: Reward = -0.5\n",
      "Episode 41: Reward = -0.5\n",
      "Episode 42: Reward = -0.5\n",
      "Episode 43: Reward = -0.5\n",
      "Episode 44: Reward = -0.5\n",
      "Episode 45: Reward = -0.5\n",
      "Episode 46: Reward = -0.5\n",
      "Episode 47: Reward = -0.5\n",
      "Episode 48: Reward = -0.5\n",
      "Episode 49: Reward = -0.5\n",
      "Episode 50: Reward = -0.5\n",
      "Episode 51: Reward = -0.5\n",
      "Episode 52: Reward = -0.5\n",
      "Episode 53: Reward = -0.5\n",
      "Episode 54: Reward = -0.5\n",
      "Episode 55: Reward = -0.6\n",
      "Episode 56: Reward = -0.5\n",
      "Episode 57: Reward = -0.5\n",
      "Episode 58: Reward = -0.5\n",
      "Episode 59: Reward = -0.5\n",
      "Episode 60: Reward = -0.5\n",
      "Episode 61: Reward = -0.5\n",
      "Episode 62: Reward = -0.5\n",
      "Episode 63: Reward = -0.5\n",
      "Episode 64: Reward = -0.5\n",
      "Episode 65: Reward = -0.5\n",
      "Episode 66: Reward = -0.5\n",
      "Episode 67: Reward = -0.5\n",
      "Episode 68: Reward = -0.5\n",
      "Episode 69: Reward = -0.5\n",
      "Episode 70: Reward = -0.5\n",
      "Episode 71: Reward = -0.5\n",
      "Episode 72: Reward = -0.6\n",
      "Episode 73: Reward = -0.5\n",
      "Episode 74: Reward = -0.5\n",
      "Episode 75: Reward = -0.5\n",
      "Episode 76: Reward = -0.5\n",
      "Episode 77: Reward = -0.5\n",
      "Episode 78: Reward = -0.5\n",
      "Episode 79: Reward = -0.5\n",
      "Episode 80: Reward = -0.5\n",
      "Episode 81: Reward = -0.5\n",
      "Episode 82: Reward = -0.5\n",
      "Episode 83: Reward = -0.5\n",
      "Episode 84: Reward = -0.6\n",
      "Episode 85: Reward = -0.5\n",
      "Episode 86: Reward = -0.5\n",
      "Episode 87: Reward = -0.5\n",
      "Episode 88: Reward = -0.5\n",
      "Episode 89: Reward = -0.5\n",
      "Episode 90: Reward = -0.5\n",
      "Episode 91: Reward = -0.5\n",
      "Episode 92: Reward = -0.5\n",
      "Episode 93: Reward = -0.5\n",
      "Episode 94: Reward = -0.5\n",
      "Episode 95: Reward = -0.5\n",
      "Episode 96: Reward = -0.5\n",
      "Episode 97: Reward = -0.5\n",
      "Episode 98: Reward = -0.5\n",
      "Episode 99: Reward = -0.5\n"
     ]
    }
   ],
   "source": [
    "# adjustable evaluation run\n",
    "obs, info = env.reset()\n",
    "lstm_states = None\n",
    "episode_rewards = []\n",
    "episode_reward = 0\n",
    "episode_counts = 100  # Number of episodes for evaluation\n",
    "results = []\n",
    "\n",
    "for episode in range(episode_counts):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    lstm_states = None\n",
    "    episode_reward = 0\n",
    "    trial_history = []\n",
    "    \n",
    "    while not done:\n",
    "        action, lstm_states = model.predict(\n",
    "            obs,\n",
    "            state=lstm_states,\n",
    "            deterministic=False,\n",
    "            episode_start=np.array([done])\n",
    "        )\n",
    "        \n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # append step to trial history\n",
    "        trial_history.append({\n",
    "            \"obs\": obs,\n",
    "            \"action\": action,\n",
    "            \"reward\": reward,\n",
    "            \"info\": info\n",
    "        })\n",
    "        episode_reward += reward\n",
    "    \n",
    "    results.append({\n",
    "        \"episode\": episode,\n",
    "        \"total_reward\": episode_reward,\n",
    "        \"trials\": trial_history\n",
    "    })\n",
    "    print(f\"Episode {episode}: Reward = {episode_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's visualize how our agent behaved in this situation - first let's do simple bar graph and see what percent of episodes the agent picked the reward with the higher EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (rnn_env)",
   "language": "python",
   "name": "rnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
