{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from src.taskgym import HaydenRiskTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment\n",
    "env = HaydenRiskTrial(offer_amounts=(1,5,10), penalty_hyperactive=-5, reward_choice_made=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/bhayden/ti12/miniforge3/envs/rnn_env/lib/python3.11/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = RecurrentPPO(\"MlpLstmPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 67       |\n",
      "|    ep_rew_mean     | 21.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 201      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 128      |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 65            |\n",
      "|    ep_rew_mean          | 6.6           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 139           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 256           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8835296e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.00394       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 17.6          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    value_loss           | 36.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.6         |\n",
      "|    ep_rew_mean          | 12.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 384          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.182601e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.009        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -5.47e-06    |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.4          |\n",
      "|    ep_rew_mean          | 7.73          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 136           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7430244e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.0521       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.13          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000435     |\n",
      "|    value_loss           | 10.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.3          |\n",
      "|    ep_rew_mean          | 5.08          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 135           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 640           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015647942 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.25         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.197         |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00185      |\n",
      "|    value_loss           | 0.902         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.3        |\n",
      "|    ep_rew_mean          | 3.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 768         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000357504 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.381       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    value_loss           | 0.96        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.2          |\n",
      "|    ep_rew_mean          | 6.7           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 134           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 896           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039642584 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.00753       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00249      |\n",
      "|    value_loss           | 26.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.2         |\n",
      "|    ep_rew_mean          | 8.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022146413 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.00931      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.08         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.2        |\n",
      "|    ep_rew_mean          | 11.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 1152        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002908945 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.00159     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00573     |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.2         |\n",
      "|    ep_rew_mean          | 12.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 1280         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003469265 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.00224      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 86.4         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | 0.000203     |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 11.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 1408         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016540973 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.98         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 10.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016156589 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.0262       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.24         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 6.63         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.1        |\n",
      "|    ep_rew_mean          | 10.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 1664        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009364635 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.00869     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 8.78        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 11.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 1792         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030034226 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 10.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 1920          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032273727 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0111        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.57          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    value_loss           | 9.89          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.1        |\n",
      "|    ep_rew_mean          | 10.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.76938e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0753      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000487   |\n",
      "|    value_loss           | 7.52        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 11.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 2176          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7671532e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0788        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 12.8          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | 0.000158      |\n",
      "|    value_loss           | 27            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 12.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 2304          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9809231e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.146         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 12.6          |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 0.000151      |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 12.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 2432          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1315569e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0864        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 54.1          |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000112     |\n",
      "|    value_loss           | 110           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 12.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 2560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9050203e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.194         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.33          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -4.28e-05     |\n",
      "|    value_loss           | 19.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 11.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 2688         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.775372e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.4         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -7.16e-06    |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 64.1           |\n",
      "|    ep_rew_mean          | 11.1           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 133            |\n",
      "|    iterations           | 22             |\n",
      "|    time_elapsed         | 21             |\n",
      "|    total_timesteps      | 2816           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.10827386e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.1           |\n",
      "|    explained_variance   | -0.883         |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.46           |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -3.38e-06      |\n",
      "|    value_loss           | 5.89           |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 10.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 2944          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3872202e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -1.08         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.13          |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000117     |\n",
      "|    value_loss           | 3.09          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 9.8           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 3072          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6238066e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -1.39         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.328         |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    value_loss           | 1.15          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 9.77         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 3200         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001686262 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.05         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.46         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000377    |\n",
      "|    value_loss           | 7.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 9.22         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 3328         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.850878e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.0562      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.1         |\n",
      "|    ep_rew_mean          | 9.7          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 3456         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.387398e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -2.71        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.111        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00065     |\n",
      "|    value_loss           | 0.708        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 9.17          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 3584          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016076677 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0307        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 75.6          |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.000386     |\n",
      "|    value_loss           | 152           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 9.61          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 3712          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042380346 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.106         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.36          |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00289      |\n",
      "|    value_loss           | 7.04          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64.1          |\n",
      "|    ep_rew_mean          | 9.14          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 3840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096280035 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0698        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 15.4          |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000874     |\n",
      "|    value_loss           | 33.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 9.96          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 3968          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046830717 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0886        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.99          |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.00229      |\n",
      "|    value_loss           | 7.99          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64           |\n",
      "|    ep_rew_mean          | 9.53         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.508664e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000131    |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 9.89          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 4224          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7020225e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.479        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.34          |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | 0.000147      |\n",
      "|    value_loss           | 3.36          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 9.48          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 4352          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4933757e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0559        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 62.4          |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.000109     |\n",
      "|    value_loss           | 128           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 9.49          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 4480          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9839965e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.207         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.63          |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.000278     |\n",
      "|    value_loss           | 10.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 9.1           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 4608          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1320226e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.0217       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.26          |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | 5.23e-05      |\n",
      "|    value_loss           | 3.16          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 8.76          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 4736          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4618505e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -2.11         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.8           |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | 5.21e-05      |\n",
      "|    value_loss           | 2.67          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 64         |\n",
      "|    ep_rew_mean          | 9.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 133        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 4864       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 2.0843e-06 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.091      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -6.1e-05   |\n",
      "|    value_loss           | 28.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64           |\n",
      "|    ep_rew_mean          | 8.75         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 4992         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.729792e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.52         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000569    |\n",
      "|    value_loss           | 9.36         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 64            |\n",
      "|    ep_rew_mean          | 8.42          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 133           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 38            |\n",
      "|    total_timesteps      | 5120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6330894e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -1.19         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.253         |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00059      |\n",
      "|    value_loss           | 0.961         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_recurrent.ppo_recurrent.RecurrentPPO at 0x7f3c6398f410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run 5000 training runs\n",
    "model.learn(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Reward = -4.100000000000001\n",
      "Episode 1: Reward = -4.5\n",
      "Episode 2: Reward = -3.900000000000002\n",
      "Episode 3: Reward = 1.8999999999999981\n",
      "Episode 4: Reward = -4.5\n",
      "Episode 5: Reward = -3.300000000000002\n",
      "Episode 6: Reward = -3.100000000000002\n",
      "Episode 7: Reward = 46.1\n",
      "Episode 8: Reward = -4.799999999999999\n",
      "Episode 9: Reward = -3.100000000000002\n",
      "Episode 10: Reward = 21.599999999999998\n",
      "Episode 11: Reward = 21.699999999999996\n",
      "Episode 12: Reward = -3.700000000000002\n",
      "Episode 13: Reward = -4.300000000000001\n",
      "Episode 14: Reward = -4.300000000000001\n",
      "Episode 15: Reward = -3.300000000000002\n",
      "Episode 16: Reward = -4.100000000000001\n",
      "Episode 17: Reward = -4.000000000000002\n",
      "Episode 18: Reward = -3.5000000000000018\n",
      "Episode 19: Reward = 21.9\n",
      "Episode 20: Reward = -3.6000000000000014\n",
      "Episode 21: Reward = 21.1\n",
      "Episode 22: Reward = -3.400000000000002\n",
      "Episode 23: Reward = -4.4\n",
      "Episode 24: Reward = -4.699999999999999\n",
      "Episode 25: Reward = -4.999999999999998\n",
      "Episode 26: Reward = -3.800000000000002\n",
      "Episode 27: Reward = -3.700000000000001\n",
      "Episode 28: Reward = 1.4999999999999982\n",
      "Episode 29: Reward = 22.0\n",
      "Episode 30: Reward = -2.6000000000000014\n",
      "Episode 31: Reward = 21.799999999999997\n",
      "Episode 32: Reward = -4.300000000000001\n",
      "Episode 33: Reward = -4.799999999999999\n",
      "Episode 34: Reward = -4.899999999999999\n",
      "Episode 35: Reward = 46.3\n",
      "Episode 36: Reward = 21.4\n",
      "Episode 37: Reward = 21.9\n",
      "Episode 38: Reward = -3.200000000000002\n",
      "Episode 39: Reward = 21.699999999999996\n",
      "Episode 40: Reward = -4.5\n",
      "Episode 41: Reward = -3.0000000000000018\n",
      "Episode 42: Reward = -4.5\n",
      "Episode 43: Reward = -4.200000000000001\n",
      "Episode 44: Reward = -4.300000000000001\n",
      "Episode 45: Reward = -3.8000000000000007\n",
      "Episode 46: Reward = -4.200000000000001\n",
      "Episode 47: Reward = 2.1999999999999984\n",
      "Episode 48: Reward = 21.5\n",
      "Episode 49: Reward = 21.5\n",
      "Episode 50: Reward = 46.5\n",
      "Episode 51: Reward = -3.100000000000002\n",
      "Episode 52: Reward = 47.2\n",
      "Episode 53: Reward = -4.000000000000002\n",
      "Episode 54: Reward = -4.000000000000002\n",
      "Episode 55: Reward = -4.5\n",
      "Episode 56: Reward = 21.9\n",
      "Episode 57: Reward = -3.800000000000002\n",
      "Episode 58: Reward = -4.300000000000001\n",
      "Episode 59: Reward = -3.300000000000002\n",
      "Episode 60: Reward = -3.800000000000002\n",
      "Episode 61: Reward = -3.200000000000002\n",
      "Episode 62: Reward = -3.400000000000002\n",
      "Episode 63: Reward = -4.100000000000001\n",
      "Episode 64: Reward = -3.8000000000000007\n",
      "Episode 65: Reward = -4.0\n",
      "Episode 66: Reward = -3.800000000000002\n",
      "Episode 67: Reward = -3.6000000000000014\n",
      "Episode 68: Reward = -4.899999999999999\n",
      "Episode 69: Reward = -3.400000000000002\n",
      "Episode 70: Reward = -2.7000000000000015\n",
      "Episode 71: Reward = -3.300000000000002\n",
      "Episode 72: Reward = 46.1\n",
      "Episode 73: Reward = -3.0000000000000018\n",
      "Episode 74: Reward = -4.200000000000001\n",
      "Episode 75: Reward = -3.100000000000002\n",
      "Episode 76: Reward = 21.799999999999997\n",
      "Episode 77: Reward = -4.999999999999998\n",
      "Episode 78: Reward = -4.699999999999999\n",
      "Episode 79: Reward = -3.200000000000002\n",
      "Episode 80: Reward = -3.700000000000002\n",
      "Episode 81: Reward = 47.2\n",
      "Episode 82: Reward = -4.300000000000001\n",
      "Episode 83: Reward = -4.100000000000001\n",
      "Episode 84: Reward = -3.900000000000002\n",
      "Episode 85: Reward = -3.0000000000000018\n",
      "Episode 86: Reward = -5.099999999999998\n",
      "Episode 87: Reward = 21.699999999999996\n",
      "Episode 88: Reward = -2.9000000000000017\n",
      "Episode 89: Reward = -3.300000000000002\n",
      "Episode 90: Reward = -4.699999999999999\n",
      "Episode 91: Reward = 46.8\n",
      "Episode 92: Reward = 47.0\n",
      "Episode 93: Reward = -4.699999999999999\n",
      "Episode 94: Reward = -3.100000000000002\n",
      "Episode 95: Reward = -4.899999999999999\n",
      "Episode 96: Reward = 1.8999999999999981\n",
      "Episode 97: Reward = 46.5\n",
      "Episode 98: Reward = 47.0\n",
      "Episode 99: Reward = 46.4\n"
     ]
    }
   ],
   "source": [
    "# adjustable evaluation run\n",
    "obs, info = env.reset()\n",
    "lstm_states = None\n",
    "episode_rewards = []\n",
    "episode_reward = 0\n",
    "episode_counts = 100  # Number of episodes for evaluation\n",
    "results = []\n",
    "\n",
    "for episode in range(episode_counts):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    lstm_states = None\n",
    "    episode_reward = 0\n",
    "    trial_history = []\n",
    "    \n",
    "    while not done:\n",
    "        action, lstm_states = model.predict(\n",
    "            obs,\n",
    "            state=lstm_states,\n",
    "            deterministic=False,\n",
    "            episode_start=np.array([done])\n",
    "        )\n",
    "        \n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # append step to trial history\n",
    "        trial_history.append({\n",
    "            \"obs\": obs,\n",
    "            \"action\": action,\n",
    "            \"reward\": reward,\n",
    "            \"info\": info\n",
    "        })\n",
    "        episode_reward += reward\n",
    "    \n",
    "    results.append({\n",
    "        \"episode\": episode,\n",
    "        \"total_reward\": episode_reward,\n",
    "        \"trials\": trial_history\n",
    "    })\n",
    "    print(f\"Episode {episode}: Reward = {episode_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's visualize how our agent behaved in this situation - first let's do simple bar graph and see what percent of episodes the agent picked the reward with the higher EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (rnn_env)",
   "language": "python",
   "name": "rnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
