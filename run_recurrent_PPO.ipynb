{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from src.taskgym import HaydenRiskTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment\n",
    "env = HaydenRiskTrial(offer_amounts=(1,5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/bhayden/ti12/miniforge3/envs/rnn_env/lib/python3.11/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = RecurrentPPO(\"MlpLstmPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 68       |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 174      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 128      |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 12.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 256          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.240863e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.000634     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000706    |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 123           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 384           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5921806e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.102         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.44          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000576     |\n",
      "|    value_loss           | 1.04          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 14            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0984475e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.00821       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 72.5          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000613     |\n",
      "|    value_loss           | 146           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 640           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6160927e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.00147       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 16            |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -5.57e-05     |\n",
      "|    value_loss           | 32.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 13           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 768          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.154195e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 60.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 1.64e-05     |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 12.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 896           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1128678e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.659        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.04          |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.000507     |\n",
      "|    value_loss           | 4.42          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.9          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 1024          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012581097 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0559        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    value_loss           | 24.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 17.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 1152          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.4924046e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0658        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 109           |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | 0.001         |\n",
      "|    value_loss           | 224           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 20.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 1280          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6123903e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.108         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 11.4          |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -6.48e-05     |\n",
      "|    value_loss           | 23.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 18           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 1408         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.688068e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 1.89e-05     |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6824342e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.841        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.04          |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -4.5e-05      |\n",
      "|    value_loss           | 10.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 18.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 1664          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2351742e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.84         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.3           |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -6.16e-05     |\n",
      "|    value_loss           | 9.51          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 17.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 1792          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0617687e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0694        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 106           |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | 2.35e-06      |\n",
      "|    value_loss           | 214           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 17.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 1920          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011120178 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.037         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    value_loss           | 22.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 15.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.585056e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.00066     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000162    |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 2176          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9970037e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -1.2          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.09          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000726     |\n",
      "|    value_loss           | 6.36          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 16.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 2304        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.06884e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.000127    |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 15.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 2432         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.542556e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.07         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.52         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000827    |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 2560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.7592285e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.495        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.01          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000943     |\n",
      "|    value_loss           | 10.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 17            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 2688          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6049397e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0493        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 52            |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | 0.000142      |\n",
      "|    value_loss           | 104           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 18.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 2816         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.326669e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.0707       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58.8         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -9.67e-05    |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 18           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 2944         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.360933e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.0657       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 99.6         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -5.66e-05    |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 17.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006067343 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.0132       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 17.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001839221 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.00895     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000226   |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 16.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 3328        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006144407 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 68         |\n",
      "|    ep_rew_mean          | 16         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 3456       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00448136 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -0.555     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.19       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | 0.00406    |\n",
      "|    value_loss           | 3.37       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 16.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 3584          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047396077 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.22         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.401         |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | 0.0011        |\n",
      "|    value_loss           | 2.01          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 68            |\n",
      "|    ep_rew_mean          | 15.9          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 3712          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.6791424e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.0201        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 78.5          |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.000295     |\n",
      "|    value_loss           | 160           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 16.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 3840        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005371993 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.344      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.639       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 16          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 3968        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011798913 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.00133     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.6        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | 15.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001187399 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.924       |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.000446     |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.9         |\n",
      "|    ep_rew_mean          | 14.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 4224         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015426637 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | -0.352       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000693    |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.8         |\n",
      "|    ep_rew_mean          | 15           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 4352         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012304485 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.97        |\n",
      "|    explained_variance   | -0.286       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.408        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000643    |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.6         |\n",
      "|    ep_rew_mean          | 14.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 4480         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031385985 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 68           |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 0.00279      |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 67.5       |\n",
      "|    ep_rew_mean          | 14.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 4608       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02099046 |\n",
      "|    clip_fraction        | 0.0727     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.842     |\n",
      "|    explained_variance   | -0.306     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.747      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    value_loss           | 1.89       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 67.4          |\n",
      "|    ep_rew_mean          | 13.9          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 4736          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048249634 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.721        |\n",
      "|    explained_variance   | 0.0454        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | 0.00231       |\n",
      "|    value_loss           | 31            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.3         |\n",
      "|    ep_rew_mean          | 13.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 4864         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035214438 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | -0.416       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.704        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.2         |\n",
      "|    ep_rew_mean          | 13.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 4992         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019316031 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.646       |\n",
      "|    explained_variance   | -0.415       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.159        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 0.669        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.2        |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014738351 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_recurrent.ppo_recurrent.RecurrentPPO at 0x7fbc5eb7d4d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run 5000 training runs\n",
    "model.learn(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Reward = -2.3000000000000007\n",
      "Episode 1: Reward = -2.1000000000000005\n",
      "Episode 2: Reward = -2.700000000000001\n",
      "Episode 3: Reward = -2.3000000000000007\n",
      "Episode 4: Reward = -2.2000000000000006\n",
      "Episode 5: Reward = -2.2000000000000006\n",
      "Episode 6: Reward = -2.700000000000001\n",
      "Episode 7: Reward = -2.500000000000001\n",
      "Episode 8: Reward = -2.1000000000000005\n",
      "Episode 9: Reward = -2.400000000000001\n",
      "Episode 10: Reward = -2.0000000000000004\n",
      "Episode 11: Reward = -2.3000000000000007\n",
      "Episode 12: Reward = -2.2000000000000006\n",
      "Episode 13: Reward = -2.500000000000001\n",
      "Episode 14: Reward = -3.2000000000000015\n",
      "Episode 15: Reward = -3.1000000000000014\n",
      "Episode 16: Reward = -2.800000000000001\n",
      "Episode 17: Reward = -2.3000000000000007\n",
      "Episode 18: Reward = -2.3000000000000007\n",
      "Episode 19: Reward = -1.8000000000000005\n",
      "Episode 20: Reward = 3.7\n",
      "Episode 21: Reward = -2.800000000000001\n",
      "Episode 22: Reward = -2.2000000000000006\n",
      "Episode 23: Reward = -1.8000000000000005\n",
      "Episode 24: Reward = -1.5000000000000002\n",
      "Episode 25: Reward = -2.600000000000001\n",
      "Episode 26: Reward = -2.600000000000001\n",
      "Episode 27: Reward = -2.600000000000001\n",
      "Episode 28: Reward = -2.400000000000001\n",
      "Episode 29: Reward = -2.700000000000001\n",
      "Episode 30: Reward = -2.0000000000000004\n",
      "Episode 31: Reward = 48.1\n",
      "Episode 32: Reward = 23.1\n",
      "Episode 33: Reward = -2.400000000000001\n",
      "Episode 34: Reward = -2.0000000000000004\n",
      "Episode 35: Reward = -2.2000000000000006\n",
      "Episode 36: Reward = -1.7000000000000004\n",
      "Episode 37: Reward = -1.7000000000000004\n",
      "Episode 38: Reward = -2.700000000000001\n",
      "Episode 39: Reward = -2.2000000000000006\n",
      "Episode 40: Reward = -1.5000000000000002\n",
      "Episode 41: Reward = -2.500000000000001\n",
      "Episode 42: Reward = -2.3000000000000007\n",
      "Episode 43: Reward = -1.8000000000000005\n",
      "Episode 44: Reward = -2.400000000000001\n",
      "Episode 45: Reward = 48.4\n",
      "Episode 46: Reward = -2.400000000000001\n",
      "Episode 47: Reward = -2.1000000000000005\n",
      "Episode 48: Reward = 48.1\n",
      "Episode 49: Reward = -1.5000000000000002\n",
      "Episode 50: Reward = -2.2000000000000006\n",
      "Episode 51: Reward = -2.800000000000001\n",
      "Episode 52: Reward = -2.600000000000001\n",
      "Episode 53: Reward = -2.400000000000001\n",
      "Episode 54: Reward = -2.0000000000000004\n",
      "Episode 55: Reward = -2.1000000000000005\n",
      "Episode 56: Reward = -2.600000000000001\n",
      "Episode 57: Reward = -1.6000000000000003\n",
      "Episode 58: Reward = -2.700000000000001\n",
      "Episode 59: Reward = 23.6\n",
      "Episode 60: Reward = -2.1000000000000005\n",
      "Episode 61: Reward = -2.500000000000001\n",
      "Episode 62: Reward = -2.500000000000001\n",
      "Episode 63: Reward = -2.600000000000001\n",
      "Episode 64: Reward = -1.8000000000000005\n",
      "Episode 65: Reward = -1.9000000000000006\n",
      "Episode 66: Reward = -1.6000000000000003\n",
      "Episode 67: Reward = -2.0000000000000004\n",
      "Episode 68: Reward = -1.9000000000000006\n",
      "Episode 69: Reward = 22.7\n",
      "Episode 70: Reward = -2.500000000000001\n",
      "Episode 71: Reward = -1.4000000000000001\n",
      "Episode 72: Reward = -2.700000000000001\n",
      "Episode 73: Reward = 23.9\n",
      "Episode 74: Reward = -2.3000000000000007\n",
      "Episode 75: Reward = -1.4000000000000001\n",
      "Episode 76: Reward = 48.2\n",
      "Episode 77: Reward = -2.3000000000000007\n",
      "Episode 78: Reward = -1.8000000000000005\n",
      "Episode 79: Reward = -2.400000000000001\n",
      "Episode 80: Reward = -2.800000000000001\n",
      "Episode 81: Reward = -2.0000000000000004\n",
      "Episode 82: Reward = -2.2000000000000006\n",
      "Episode 83: Reward = -2.0000000000000004\n",
      "Episode 84: Reward = -2.3000000000000007\n",
      "Episode 85: Reward = -2.400000000000001\n",
      "Episode 86: Reward = -2.500000000000001\n",
      "Episode 87: Reward = -2.1000000000000005\n",
      "Episode 88: Reward = -2.2000000000000006\n",
      "Episode 89: Reward = -1.7000000000000004\n",
      "Episode 90: Reward = -2.500000000000001\n",
      "Episode 91: Reward = -2.600000000000001\n",
      "Episode 92: Reward = -2.400000000000001\n",
      "Episode 93: Reward = -1.8000000000000005\n",
      "Episode 94: Reward = -2.800000000000001\n",
      "Episode 95: Reward = -2.500000000000001\n",
      "Episode 96: Reward = -2.700000000000001\n",
      "Episode 97: Reward = -2.400000000000001\n",
      "Episode 98: Reward = -2.700000000000001\n",
      "Episode 99: Reward = -1.7000000000000004\n"
     ]
    }
   ],
   "source": [
    "# adjustable evaluation run\n",
    "obs, info = env.reset()\n",
    "lstm_states = None\n",
    "episode_rewards = []\n",
    "episode_reward = 0\n",
    "episode_counts = 100  # Number of episodes for evaluation\n",
    "results = []\n",
    "\n",
    "for episode in range(episode_counts):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    lstm_states = None\n",
    "    episode_reward = 0\n",
    "    trial_history = []\n",
    "    \n",
    "    while not done:\n",
    "        action, lstm_states = model.predict(\n",
    "            obs,\n",
    "            state=lstm_states,\n",
    "            deterministic=False,\n",
    "            episode_start=np.array([done])\n",
    "        )\n",
    "        \n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # append step to trial history\n",
    "        trial_history.append({\n",
    "            \"obs\": obs,\n",
    "            \"action\": action,\n",
    "            \"reward\": reward,\n",
    "            \"info\": info\n",
    "        })\n",
    "        episode_reward += reward\n",
    "    \n",
    "    results.append({\n",
    "        \"episode\": episode,\n",
    "        \"total_reward\": episode_reward,\n",
    "        \"trials\": trial_history\n",
    "    })\n",
    "    print(f\"Episode {episode}: Reward = {episode_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's visualize how our agent behaved in this situation - first let's do simple bar graph and see what percent of episodes the agent picked the reward with the higher EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (rnn_env)",
   "language": "python",
   "name": "rnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
